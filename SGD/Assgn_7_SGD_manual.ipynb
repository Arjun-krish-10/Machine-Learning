{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assgn - 7 - SGD manual.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JWSmbnVGzd7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52126123-cf7d-49d3-9fd5-cef6936017b7"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(X_train)\n",
        "x_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3374bd-371f-4570-a006-1f4818322d7e"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd1TZkyUK25u"
      },
      "source": [
        "# x_train[:5] == X_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d290d0f6-13af-478e-d9c1-474bd78774db"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc0de9c-4262-4da7-9f00-993069385059"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 10 epochs took 0.11 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8fd431-587b-464c-c6e7-496b62616a31"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w = np.zeros_like(dim)\n",
        "    b = 0\n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b46f17-c908-4449-c0d6-4b694d47e097"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRhlZPO8fWcW",
        "outputId": "15b24c26-87d9-49d4-f737-4c55b86602b8"
      },
      "source": [
        "np.array(w).shape,dim.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15,), (15,))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d200ec7c-f3e4-4ace-8b59-4eb3f0ff972a"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    s = 1/(1+np.exp(-z))\n",
        "\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bfae52f-eaf7-4757-faad-6c1015f700a2"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    temp = 0\n",
        "   \n",
        "    for i in range(y_true.shape[0]):\n",
        "      temp1 = y_true[i]*np.log10(y_pred[i]) + (1-y_true[i]) * np.log10(1 - y_pred[i] ) \n",
        "      temp +=  temp1\n",
        "    loss = -1 * temp/len(y_true)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a05654-780f-4cf1-974b-39310af490bf"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=np.array([1,1,0,1,0])\n",
        "pred=np.array([0.9,0.8,0.1,0.8,0.2])\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    t1 = sigmoid(np.dot(x,w.T) + b)\n",
        "    t2 = y - t1\n",
        "    t3 = x*t2\n",
        "    t4 = (alpha/N) * w\n",
        "    dw = t3 - t4\n",
        "    # dw = (x * ( y - sigmoid(np.dot(x,w.T) + b))) - (alpha/N) * w\n",
        "    return dw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2e4765-c8d4-4fdd-fd75-f2d97ef8cb85"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        " def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     t1 = sigmoid(np.dot(x,w.T) + b)\n",
        "     db = (y - t1)#*t1*(1-t1)\n",
        "     return db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d14b019-363a-4471-d3e5-2381e12e47dc"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7f-Y4UNZ-KZ"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_J2f2SoKcBC",
        "outputId": "03eefc8f-c1ad-4915-b666-173c45fba817"
      },
      "source": [
        "x_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.39348337, -0.19771903, -0.15037836, -0.21528098, -1.28594363,\n",
              "        -0.66049132,  0.04140556, -0.22680269, -0.511055  , -0.42871073,\n",
              "         0.4210912 ,  0.22560347, -0.6624427 , -0.68888516,  0.56015427],\n",
              "       [ 0.73641397, -0.33354604,  0.13809494, -0.95826082, -0.28406545,\n",
              "        -0.17626204,  0.95984198, -0.21664866, -0.35917115, -1.14358811,\n",
              "        -0.42753462, -0.2107782 ,  0.07936129,  0.39617118, -0.68713223],\n",
              "       [ 0.85834602,  0.24584928, -0.38694362,  0.219608  , -0.1527049 ,\n",
              "        -0.16767779,  0.61663602, -0.7524124 , -0.23998409, -0.08458355,\n",
              "        -0.18500353,  0.20769245,  0.04608795,  0.92475102, -1.05700576],\n",
              "       [-0.89373392, -0.5824285 ,  0.95250128, -2.06345936,  2.11701453,\n",
              "        -0.07741948, -0.60843902,  0.19971306,  0.6390822 ,  1.2571824 ,\n",
              "        -0.49253608, -0.56448091,  2.18694682,  0.15843084, -0.98438437],\n",
              "       [ 0.6607519 ,  0.44779601,  0.51996572,  0.56720448, -0.0661378 ,\n",
              "         0.09074473,  3.49314221, -0.48470311,  2.15096975, -0.51464251,\n",
              "        -3.15696668,  1.17643836, -1.05407024,  4.02941662, -1.88487887]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4n08HtqPPmw",
        "outputId": "0494eb20-e1b1-463a-a0e9-d03117ad59e3"
      },
      "source": [
        "X_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.57349184,  -0.19015688,  -0.06584143,  -0.86990562,\n",
              "         -2.80927706,  -1.43345052,   0.35862361,   0.24627836,\n",
              "         -2.25803168,  -0.87761289,   2.31023199,  -0.3484947 ,\n",
              "         -2.2575668 ,  -1.93628665,   1.65242231],\n",
              "       [  1.827818  ,  -0.45810992,   0.47407375,  -2.17856544,\n",
              "         -1.16453085,  -0.59906384,   2.24400146,   0.2664526 ,\n",
              "         -1.59252721,  -2.3705834 ,  -1.14068014,  -1.83108915,\n",
              "         -0.32123197,   0.31287131,  -1.494433  ],\n",
              "       [  2.08695359,   0.6848935 ,  -0.508604  ,  -0.10390674,\n",
              "         -0.94888112,  -0.58427211,   1.53946393,  -0.7980144 ,\n",
              "         -1.07028919,  -0.15892778,  -0.15443456,  -0.40934689,\n",
              "         -0.40808552,   1.40853752,  -2.42760955],\n",
              "       [ -1.63664734,  -0.94909336,   1.99834081,  -4.12522514,\n",
              "          2.77723297,  -0.42874594,  -0.97538552,   1.0936891 ,\n",
              "          2.78148657,   2.64325488,  -1.4050067 ,  -3.03278418,\n",
              "          5.18020963,  -0.17992851,  -2.2443886 ],\n",
              "       [  1.66701747,   1.08328437,   1.18879442,   0.50833807,\n",
              "         -0.80676713,  -0.13897828,   7.44439206,  -0.26612378,\n",
              "          9.40607441,  -1.0570753 , -12.23983597,   2.88194013,\n",
              "         -3.27983423,   7.84404055,  -4.51630121]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "\n",
        "    w , b = initialize_weights(X_train[0])\n",
        "\n",
        "    \n",
        "    global test_loss\n",
        "    global train_loss \n",
        "\n",
        "# for every epoch\n",
        "    for k in range(epochs):\n",
        "        \n",
        "        # for every data point(X_train,y_train)   # considering batch size = 1\n",
        "        for a in range(len(X_train)):\n",
        "        \n",
        "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "            \n",
        "            dw = gradient_dw(X_train[a],y_train[a],w,b,alpha,len(X_train))\n",
        "           #compute gradient w.r.to b (call the gradient_db() function)\n",
        "            db = gradient_db(X_train[a],y_train[a],w,b)\n",
        "           #update w, b\n",
        "            w = w + eta0*dw\n",
        "            b = b + eta0*db  \n",
        "\n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "       \n",
        "        y = sigmoid(np.dot(X_train,w) + b) #+ eps\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "\n",
        "        loss_train = logloss(y_train,y)\n",
        "        # store all the train loss values in a list\n",
        "        train_loss.append(loss_train)\n",
        "\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        y_hat_pred = sigmoid(np.dot(X_test,w.T) + b)\n",
        "\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        loss_test = logloss(y_test,y_hat_pred)\n",
        "\n",
        "        # store all the test loss values in a list       \n",
        "        test_loss.append(loss_test)\n",
        "\n",
        "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
        " \n",
        "        if k!= 0:\n",
        "          if round(train_loss[k],5) == round(train_loss[k-1],5):\n",
        "            print(k)\n",
        "            print('Minimum reached')\n",
        "            return w,b            \n",
        "               \n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e712ae-01e3-4c17-8597-762ad4e8be70"
      },
      "source": [
        "test_loss = []\n",
        "train_loss = []\n",
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=50\n",
        "w,b = train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)\n",
        "print(w,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "Minimum reached\n",
            "[-0.42696913  0.19215659 -0.14739301  0.33812031 -0.21734813  0.56797156\n",
            " -0.44523767 -0.09066632  0.22018456  0.17211202  0.1972539   0.00063806\n",
            " -0.07984243  0.33896599  0.02262496] -0.8743921634421901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31X3WxyXLNxK",
        "outputId": "5d6eb4cd-b963-4a0e-ad02-f6bd97bb1ead"
      },
      "source": [
        "train_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17545748442854608,\n",
              " 0.16867157050333045,\n",
              " 0.1663916799246292,\n",
              " 0.1653682753740316,\n",
              " 0.16485707459547086,\n",
              " 0.16458820012928269,\n",
              " 0.16444271323364384,\n",
              " 0.16436263615826985,\n",
              " 0.16431806946667749,\n",
              " 0.16429307374132512,\n",
              " 0.1642789743093407,\n",
              " 0.16427098545835503,\n",
              " 0.16426644191003525]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrjudZCsHwXA"
      },
      "source": [
        "# test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdcYxVCQcWb"
      },
      "source": [
        "# for i in np.dot(X_train[:5],w):\n",
        "    # print(sigmoid(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfpG3F_xVFPp",
        "outputId": "1e124933-4c12-4a4b-b55c-886089abab73"
      },
      "source": [
        "clf.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "         0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "         0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BflsOGGVMJ8",
        "outputId": "b8bb8eb8-2ee4-4d76-e4ea-1728cd3a0b59"
      },
      "source": [
        "clf.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8531383])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1077c897-e03b-4797-81a9-5c32377c4300"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-3.60221756e-03,  6.68093309e-03,  1.19735165e-03,\n",
              "         -3.32375717e-03, -9.16142288e-03,  7.80577681e-03,\n",
              "          7.18715292e-03,  3.42180511e-03,  1.09113645e-02,\n",
              "         -8.72923967e-03,  2.01996277e-04, -3.58109893e-03,\n",
              "         -2.38735003e-04,  4.37975195e-04, -4.22523777e-05]]),\n",
              " array([-0.02125387]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhP_sizCvBAy"
      },
      "source": [
        "It can be seen that the difference between the Sklearn implementation of SGD and manual implementaion is not significantly large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba0b08a-d5c1-4835-e361-dcbff2f5d7fa"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.24888\n",
            "1.24688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k28U1xDsLIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "417db1a5-ff5c-41bd-811e-1270c3da4188"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "epoch = [i for i in range(1,len(train_loss) + 1,1)]\n",
        "\n",
        "plt.plot(epoch,train_loss , label='train_log_loss')\n",
        "plt.plot(epoch,test_loss, label='test_log_loss')\n",
        "plt.xlabel(\"epoch number\")\n",
        "plt.ylabel(\"log loss\")\n",
        "plt.title('EPOCH vs LOG-LOSS')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMokBfs3-2PY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}