{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Assgn -  8E&F_LR_SVM_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HExLQrE4ZxR"
      },
      "source": [
        "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LuKrFzC4ZxV"
      },
      "source": [
        "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wES-wWN4ZxX"
      },
      "source": [
        "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
        "\n",
        "Check the documentation for better understanding of these attributes: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
        "\n",
        "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
        "\n",
        "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
        "\n",
        "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
        "\n",
        "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
        "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
        "\n",
        "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
        "\n",
        "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z830CfMk4Zxa"
      },
      "source": [
        "## Task E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuBxHiCQ4Zxc"
      },
      "source": [
        "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
        "\n",
        "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
        "\n",
        "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCgMNEvI4Zxf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUNIqCe4Zxn"
      },
      "source": [
        "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHie1zqH4Zxt"
      },
      "source": [
        "### Pseudo code\n",
        "\n",
        "clf = SVC(gamma=0.001, C=100.)<br>\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
        "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
        "    \n",
        "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
        "\n",
        "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h43kDT3M41u5"
      },
      "source": [
        "# you can write your code here\n",
        "\n",
        "#Splitting the data to train, cv, test\n",
        "import warnings \n",
        "\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_test,y_tr,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "x_train,x_cv,y_train,y_cv = train_test_split(x_tr,y_tr,test_size=0.25,random_state=42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzVd_RSeuS8x",
        "outputId": "8d63a03a-69da-45de-f034-5a071f149cfc"
      },
      "source": [
        "print(x_train.shape,x_cv.shape,x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000, 5) (1000, 5) (1000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1EU-sTRusMz",
        "outputId": "e0d7e413-0e84-4384-9013-ab0a74c39dec"
      },
      "source": [
        "#Initializing the model\n",
        "\n",
        "model = SVC(gamma=0.001,C=100,random_state=42)\n",
        "model.fit(x_train,y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V67sAYGq4s7C",
        "outputId": "b266ed90-c63e-405b-9282-2ee3c20cc9ed"
      },
      "source": [
        "model.support_vectors_.shape            #each support vector"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3iux8uq4xbo"
      },
      "source": [
        "# model.support_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tINvrbMQ7Qfl",
        "outputId": "ad1a5843-e064-44f2-ffc0-7a70d438bb7c"
      },
      "source": [
        "model.dual_coef_.shape                  #alpha*yi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 568)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozUrkf4BuxoC"
      },
      "source": [
        "def decision_function(x_cv,intercept,gamma,coef,sv):\n",
        "  result = []\n",
        "  \n",
        "  for xq in x_cv:\n",
        "    final = 0\n",
        "    for j,s_v in enumerate(sv):                                                 #for every support vector\n",
        "      final += coef[0][j]*np.exp(-gamma * np.linalg.norm(s_v - xq)**2)          # calculating the dual form including the RBF kernel\n",
        "    result.append(final + intercept)                                            # adding the intercept\n",
        "  return np.array(result)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7tbxYap8NW7"
      },
      "source": [
        "dec_fn = decision_function(x_cv,model.intercept_,model.gamma,model.dual_coef_,model.support_vectors_)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uZdQGrK8pbj",
        "outputId": "c00aab13-5c21-4088-e04f-4767a265ab23"
      },
      "source": [
        "np.array(dec_fn).ravel()[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.87725032, -1.11743611, -3.55849268, -0.63350034, -1.18015501,\n",
              "       -1.26230537, -3.31529473, -2.41371053, -2.40420402, -1.40470136])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkh_nev583Ci",
        "outputId": "9dee7d3e-19c6-4892-d6ef-dfa4e1d3bf21"
      },
      "source": [
        "model.decision_function(x_cv)[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.87725032, -1.11743611, -3.55849268, -0.63350034, -1.18015501,\n",
              "       -1.26230537, -3.31529473, -2.41371053, -2.40420402, -1.40470136])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2E2-9ON91sY"
      },
      "source": [
        "It can be seen that, the values of the decision function model and that of manual implementation is same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HbyxmR990RD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0bKCboN4Zxu"
      },
      "source": [
        "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMn7OEN94Zxw"
      },
      "source": [
        "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
        "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0n5EFkx4Zxz"
      },
      "source": [
        "## TASK F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0HOqVJq4Zx1"
      },
      "source": [
        "\n",
        "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
        "\n",
        "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
        "\n",
        "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
        "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
        "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
        "\n",
        "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9LqGuD0jp8I"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w = np.zeros_like(dim)\n",
        "    b = 0\n",
        "    return w,b\n",
        "\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    s = 1/(1+np.exp(z))\n",
        "\n",
        "    return s\n",
        "\n",
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    temp = 0\n",
        "   \n",
        "    for i in range(y_true.shape[0]):\n",
        "    \n",
        "        temp1 = y_true[i]*np.log10(y_pred[i]) + (1-y_true[i]) * np.log10(1 - y_pred[i] ) \n",
        "        temp +=  temp1\n",
        "    loss = -1 * temp/len(y_true)\n",
        "    return loss\n",
        "\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    t1 = sigmoid(np.dot(x,w.T) + b)\n",
        "    t2 = y - t1\n",
        "    t3 = x*t2\n",
        "    t4 = (alpha/N) * w\n",
        "    dw = t3 - t4\n",
        "    # dw = (x * ( y - sigmoid(np.dot(x,w.T) + b))) - (alpha/N) * w\n",
        "    return dw\n",
        "\n",
        "def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     t1 = sigmoid(np.dot(x,w.T) + b)\n",
        "     db = (y - t1)#*t1*(1-t1)\n",
        "     return db\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn9wUamxsgQY"
      },
      "source": [
        "##Calculating y+ and y-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrNrXdkjm6sA"
      },
      "source": [
        "#  n_pos = y_cv.sum()\n",
        "#  n_neg = len(y_cv) - n_pos "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKoMqWDrpcS"
      },
      "source": [
        " n_pos = y_train.sum()\n",
        " n_neg = len(y_train) - n_pos "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ8Q6Od4qdhI"
      },
      "source": [
        "y_pos = (n_pos + 1)/(n_pos + 2)\n",
        "y_neg = 1/(n_neg + 2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfM8RaIvcs-",
        "outputId": "56eb1f47-199a-41fc-cd70-cb4f52fbde89"
      },
      "source": [
        "y_pos,y_neg"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9989270386266095, 0.00048262548262548264)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChcKZDCWq7CT"
      },
      "source": [
        "y_cv_mod = np.where(y_cv == 0,y_neg,y_pos)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50em-c6TrR7z",
        "outputId": "9d861d95-08e8-4704-f3b5-9188b0d6f2dc"
      },
      "source": [
        "y_cv_mod.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70kfhnclvlvh"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aar4O8HQVjgn",
        "outputId": "cae83b71-4c0d-4399-a94e-794f057f162e"
      },
      "source": [
        "dec_fn.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tYV4BDAjqbu"
      },
      "source": [
        "def train(X_train,y_train,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "\n",
        "    w , b = initialize_weights(X_train[0])\n",
        "\n",
        "    \n",
        "    # global test_loss\n",
        "    global train_loss \n",
        "\n",
        "# for every epoch\n",
        "    for k in range(epochs):\n",
        "        \n",
        "        # for every data point(X_train,y_train)   # considering batch size = 1\n",
        "        for j in range(len(X_train)):\n",
        "\n",
        "            # a = np.random.choice(len(X_train))\n",
        "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "            \n",
        "            dw = gradient_dw(X_train[j],y_train[j],w,b,alpha,len(X_train))\n",
        "           #compute gradient w.r.to b (call the gradient_db() function)\n",
        "            db = gradient_db(X_train[j],y_train[j],w,b)\n",
        "           #update w, b\n",
        "            w = w - eta0*dw\n",
        "            b = b - eta0*db  \n",
        "\n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "       \n",
        "        y = sigmoid(np.dot(X_train,w) + b) #+ eps\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "\n",
        "        loss_train = logloss(y_train,y)\n",
        "        # store all the train loss values in a list\n",
        "        train_loss.append(loss_train)\n",
        "\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        # y_hat_pred = sigmoid(np.dot(X_test,w.T) + b)\n",
        "\n",
        "        # #compute the loss between predicted and actual values (call the loss function)\n",
        "        # loss_test = logloss(y_test,y_hat_pred)\n",
        "\n",
        "        # # store all the test loss values in a list       \n",
        "        # test_loss.append(loss_test)\n",
        "\n",
        "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
        " \n",
        "        if k!= 0:\n",
        "          if round(train_loss[k],5) == round(train_loss[k-1],5):\n",
        "            print(k)\n",
        "            print('Minimum reached')\n",
        "            return w,b            \n",
        "               \n",
        "    return w,b"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5jNAuhyjqij",
        "outputId": "239157f6-eaef-437e-8c57-756ab218bb15"
      },
      "source": [
        "# test_loss = []\n",
        "train_loss = []\n",
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(dec_fn)\n",
        "epochs=50\n",
        "w,b = train(dec_fn,y_cv_mod,epochs,alpha,eta0)                 # passing dec_fn(x_cv), y_cv_mod to SGD\n",
        "print(w,b)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.20811411] 0.14703437280888784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCorGDZvsgxf",
        "outputId": "8dee5451-81b6-4e41-ca3e-a7e838463c9c"
      },
      "source": [
        "train_loss[:5]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26080631808985716,\n",
              " 0.23078175404393914,\n",
              " 0.2079977730878358,\n",
              " 0.19035277504215403,\n",
              " 0.1764020677516202]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAeBExvUuua_"
      },
      "source": [
        "#Plot Epoch vs Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "75BPC5sRtX7s",
        "outputId": "732aef8c-b2ac-4ddc-a389-d08579c3cc8b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(epochs),train_loss)\n",
        "plt.title('Loss Vs Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc51JmAOsxN6"
      },
      "source": [
        "##Calculating the probability value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUYdu0KDjqpE"
      },
      "source": [
        "f_test = decision_function(x_test,model.intercept_,model.gamma,model.dual_coef_,model.support_vectors_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV08HSgyb340",
        "outputId": "c776541f-a308-42ec-8f9f-e4a5001c64bc"
      },
      "source": [
        "f_test[:7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.39679251],\n",
              "       [-1.30546589],\n",
              "       [-0.64799539],\n",
              "       [-2.51319179],\n",
              "       [-3.58985467],\n",
              "       [ 0.76482695],\n",
              "       [ 1.67435859]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxyTI2sKjqwN"
      },
      "source": [
        "y_prob = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6AmJzvajq2y"
      },
      "source": [
        "for i in range(len(x_test)):\n",
        "    p = 1/(1 + np.exp(-1*w[0]*f_test[i] + b))\n",
        "    y_prob.append(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMfoNpQ0jq9f",
        "outputId": "e62156d5-f32d-4ee5-e458-62d52fc2d58e"
      },
      "source": [
        "y_prob[:7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.00163271]),\n",
              " array([0.00267102]),\n",
              " array([0.0853637]),\n",
              " array([3.93505365e-06]),\n",
              " array([1.17352628e-08]),\n",
              " array([0.99482685]),\n",
              " array([0.99996176])]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTY7z2bd4Zx2"
      },
      "source": [
        "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM3odN1Z4Zx3"
      },
      "source": [
        "\n",
        "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
        "\n",
        "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
        "\n",
        "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
        "\n",
        "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
        "\n",
        "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
      ]
    }
  ]
}